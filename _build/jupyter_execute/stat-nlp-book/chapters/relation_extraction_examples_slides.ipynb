{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "  function code_toggle() {\n",
       "    if (code_shown){\n",
       "      $('div.input').hide('500');\n",
       "      $('#toggleButton').val('Show Code')\n",
       "    } else {\n",
       "      $('div.input').show('500');\n",
       "      $('#toggleButton').val('Hide Code')\n",
       "    }\n",
       "    code_shown = !code_shown\n",
       "  }\n",
       "\n",
       "  $( document ).ready(function(){\n",
       "    code_shown=false;\n",
       "    $('div.input').hide()\n",
       "  });\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>\n",
       "<style>\n",
       ".rendered_html td {\n",
       "    font-size: xx-large;\n",
       "    text-align: left; !important\n",
       "}\n",
       ".rendered_html th {\n",
       "    font-size: xx-large;\n",
       "    text-align: left; !important\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>\n",
    "<style>\n",
    ".rendered_html td {\n",
    "    font-size: xx-large;\n",
    "    text-align: left; !important\n",
    "}\n",
    ".rendered_html th {\n",
    "    font-size: xx-large;\n",
    "    text-align: left; !important\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../statnlpbook/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#import util\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mie\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtfutil\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "File \u001b[0;32m~/gits/nlp-course/nlp-book/stat-nlp-book/chapters/../statnlpbook/ie.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/env python3\u001b[39;00m\n\u001b[1;32m      3\u001b[0m __author__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIsabelle Augenstein\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../statnlpbook/\")\n",
    "#import util\n",
    "import ie\n",
    "import tfutil\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "np.random.seed(1337)\n",
    "tf.set_random_seed(1337)\n",
    "\n",
    "#util.execute_notebook('relation_extraction.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<!---\n",
    "Latex Macros\n",
    "-->\n",
    "$$\n",
    "\\newcommand{\\Xs}{\\mathcal{X}}\n",
    "\\newcommand{\\Ys}{\\mathcal{Y}}\n",
    "\\newcommand{\\y}{\\mathbf{y}}\n",
    "\\newcommand{\\balpha}{\\boldsymbol{\\alpha}}\n",
    "\\newcommand{\\bbeta}{\\boldsymbol{\\beta}}\n",
    "\\newcommand{\\aligns}{\\mathbf{a}}\n",
    "\\newcommand{\\align}{a}\n",
    "\\newcommand{\\source}{\\mathbf{s}}\n",
    "\\newcommand{\\target}{\\mathbf{t}}\n",
    "\\newcommand{\\ssource}{s}\n",
    "\\newcommand{\\starget}{t}\n",
    "\\newcommand{\\repr}{\\mathbf{f}}\n",
    "\\newcommand{\\repry}{\\mathbf{g}}\n",
    "\\newcommand{\\x}{\\mathbf{x}}\n",
    "\\newcommand{\\prob}{p}\n",
    "\\newcommand{\\a}{\\alpha}\n",
    "\\newcommand{\\b}{\\beta}\n",
    "\\newcommand{\\vocab}{V}\n",
    "\\newcommand{\\params}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\param}{\\theta}\n",
    "\\DeclareMathOperator{\\perplexity}{PP}\n",
    "\\DeclareMathOperator{\\argmax}{argmax}\n",
    "\\DeclareMathOperator{\\argmin}{argmin}\n",
    "\\newcommand{\\train}{\\mathcal{D}}\n",
    "\\newcommand{\\counts}[2]{\\#_{#1}(#2) }\n",
    "\\newcommand{\\length}[1]{\\text{length}(#1) }\n",
    "\\newcommand{\\indi}{\\mathbb{I}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tikzmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Relation Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Relation Extraction Approaches\n",
    "* **Pattern-Based** Relation Extraction:\n",
    "    * Extract relations via manually defined textual patterns\n",
    "* **Bootstrapping**:\n",
    "    * Iterative pattern-based relation extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* **Supervised** Relation Extraction:\n",
    "    * Train supervised model from manually labelled training examples\n",
    "* **Distantly Supervised** Relation Extraction:\n",
    "    * Supervised model with automatically annotated training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* **Universal Schema** Relation Extraction:\n",
    "    * Model relation types and surface forms in same semantic space\n",
    "* **Transfer Learning** for Relation Extraction:\n",
    "    * Use word or sentence embeddings trained on larger dataset, see representation learning lecture slides ([intro](dl-representations.ipynb), [language models](language_models_slides.ipynb), [RNN applications](rnn_slides_ucph.ipynb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "## Relation Extraction: Running Example\n",
    "* Extracting \"method used for task\" relations from sentences in computer science publications\n",
    "* The first step would normally be to detect pairs of arguments $\\mathcal{E}$. For simplicity, our training data already contains those annotations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Pattern-Based Extraction\n",
    "* The simplest relation extraction method\n",
    "* Set of textual patterns for each relation\n",
    "* Assign labels to entity pairs whose sentences match that pattern\n",
    "    * Labels: relation types or \"NONE\"\n",
    "* Data: entity pairs $\\mathcal{E}$, patterns $A$, labels $Y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ie' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_patterns, training_entpairs \u001b[38;5;241m=\u001b[39m \u001b[43mie\u001b[49m\u001b[38;5;241m.\u001b[39mreadLabelledPatternData()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Training patterns and entity pairs for relation 'method used for task'\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(training_patterns[:\u001b[38;5;241m3\u001b[39m], training_entpairs[:\u001b[38;5;241m3\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ie' is not defined"
     ]
    }
   ],
   "source": [
    "training_patterns, training_entpairs = ie.readLabelledPatternData()\n",
    "# Training patterns and entity pairs for relation 'method used for task'\n",
    "list(zip(training_patterns[:3], training_entpairs[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* Patterns: sentences where entity pairs are blanked with placeholder 'XXXXX'\n",
    "* Here: \n",
    "    * Only one relation, 'method used for task'\n",
    "    * Manually defined patterns\n",
    "* Labels for training data, no labels for test data\n",
    "* Task: 'predict' labels for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "testing_patterns, testing_entpairs = ie.readPatternData()\n",
    "# Testing patterns and entity pairs\n",
    "list(zip(testing_patterns[0:3], testing_entpairs[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Scoring model**: determine which instance belongs to which relation\n",
    "  * A pattern scoring model \\\\(s_{\\params}(\\x,y)\\\\) only has one parameter\n",
    "  * Assignes scores to each relation label \\\\(y\\\\) proportional to the matches with the set of textual patterns\n",
    "  * The final label assigned to each instance is then the one with the highest score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* Here, our pattern scoring model is even simpler since we only have patterns for one relation\n",
    "    * Final label: 'method used for task' if there is a match with a pattern, 'NONE' if no match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Closer look at pattern matching\n",
    "* Patterns in the training data: sentences where entity pairs are blanked with 'XXXXX'\n",
    "* Suggested improvement:\n",
    "    * We could use those patterns to find more sentences\n",
    "    * However, we are not likely to find many since patterns are very specific to the example\n",
    "* We need to **generalise** those patterns to less specific ones\n",
    "    * e.g. define sequence of words between each entity pair as a pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sentence_to_short_seq(sent):\n",
    "    \"\"\"\n",
    "    Returns the sequence between two arguments in a sentence, where the arguments have been masked\n",
    "    Args:\n",
    "        sent: the sentence\n",
    "    Returns:\n",
    "        the sequence between to arguments\n",
    "    \"\"\"\n",
    "    sent_toks = sent.split(\" \")\n",
    "    indeces = [i for i, ltr in enumerate(sent_toks) if ltr == \"XXXXX\"]\n",
    "    pattern = \" \".join(sent_toks[indeces[0]+1:indeces[1]])\n",
    "    return pattern\n",
    "\n",
    "print(training_patterns[0])\n",
    "sentence_to_short_seq(training_patterns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* There are many different alternatives to this method for shortening patterns\n",
    "* **Thought exercise**: \n",
    "    * what is a possible problem with this way of shortening patterns and what are better ways of generalising patterns?\n",
    "    \n",
    "Enter answer: https://tinyurl.com/y5y9fwpe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Revised pattern extraction approach\n",
    "  * Define sentence shortening / **pattern generalisation method**\n",
    "  * Apply patterns to testing instances to classify them into 'method used for task' and 'NONE'\n",
    "\n",
    "Example: return instances which contain a 'method used for task' pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pattern_extraction(training_sentences, testing_sentences):\n",
    "    \"\"\"\n",
    "    Given a set of patterns for a relation, searches for those patterns in other sentences\n",
    "    Args:\n",
    "        sent: training sentences with arguments masked, testing sentences with arguments masked\n",
    "    Returns:\n",
    "        the testing sentences which the training patterns appeared in\n",
    "    \"\"\"\n",
    "    # convert training and testing sentences to short paths to obtain patterns\n",
    "    training_patterns = set([sentence_to_short_seq(train_sent) for train_sent in training_sentences])\n",
    "    testing_patterns = [sentence_to_short_seq(test_sent) for test_sent in testing_sentences]\n",
    "    # look for match of training and testing patterns\n",
    "    testing_extractions = []\n",
    "    for i, testing_pattern in enumerate(testing_patterns):\n",
    "        if testing_pattern in training_patterns: # look for exact matches of patterns\n",
    "            testing_extractions.append(testing_sentences[i])\n",
    "    return testing_extractions\n",
    "\n",
    "pattern_extraction(training_patterns[:300], testing_patterns[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* Problems with approach: \n",
    "    * set of patterns has to be defined manually\n",
    "    * the model does not learn new patterns\n",
    "    \n",
    "\n",
    "* Next: approach which addresses those two shortcomings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Bootstrapping\n",
    "\n",
    "* Input: a set of entity pairs\n",
    "* Overall idea: extract patterns and entity pairs **iteratively**\n",
    "* One of the first algorithms: [DIPRE (Sergey Brin, 1999)](http://ilpubs.stanford.edu:8090/421/1/1999-65.pdf)\n",
    "* Two helper methods: \n",
    "    * *use entity pairs* to find/generate (more) patterns\n",
    "    * *apply patterns* to find entity pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# use patterns to find more entity pairs\n",
    "def search_for_entpairs_by_patterns(training_patterns, testing_patterns, testing_entpairs, testing_sentences):\n",
    "    testing_extractions = []\n",
    "    appearing_testing_patterns = []\n",
    "    appearing_testing_entpairs = []\n",
    "    for i, testing_pattern in enumerate(testing_patterns): # iterate over patterns\n",
    "        if testing_pattern in training_patterns: # if there is an exact match of a pattern\n",
    "            testing_extractions.append(testing_sentences[i]) # add the corresponding sentence\n",
    "            appearing_testing_patterns.append(testing_pattern) # add the pattern\n",
    "            appearing_testing_entpairs.append(testing_entpairs[i]) # add the entity pairs\n",
    "    return testing_extractions, appearing_testing_patterns, appearing_testing_entpairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# use entity pairs to find more patterns\n",
    "def search_for_patterns_by_entpairs(training_entpairs, testing_patterns, testing_entpairs, testing_sentences):\n",
    "    testing_extractions = []\n",
    "    appearing_testing_patterns = []\n",
    "    appearing_testing_entpairs = []\n",
    "    for i, testing_entpair in enumerate(testing_entpairs): # iterate over entity pairs\n",
    "        if testing_entpair in training_entpairs: # if there is an exact match of an entity pair\n",
    "            testing_extractions.append(testing_sentences[i]) # add the corresponding sentence\n",
    "            appearing_testing_entpairs.append(testing_entpair) # add the entity pair\n",
    "            appearing_testing_patterns.append(testing_patterns[i]) # add the pattern\n",
    "    return testing_extractions, appearing_testing_patterns, appearing_testing_entpairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The two helper functions are then applied iteratively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def bootstrapping_extraction(train_sents, train_entpairs, test_sents, test_entpairs, num_iter=10):\n",
    "    \"\"\"\n",
    "    Given a set of patterns and entity pairs for a relation, extracts more patterns and entity pairs iteratively\n",
    "    Args:\n",
    "        train_sents: training sentences with arguments masked\n",
    "        train_entpairs: training entity pairs\n",
    "        test_sents: testing sentences with arguments masked\n",
    "        test_entpairs: testing entity pairs\n",
    "    Returns:\n",
    "        the testing sentences which the training patterns or any of the inferred patterns appeared in\n",
    "    \"\"\"\n",
    "    # convert training and testing sentences to short paths to obtain patterns\n",
    "    train_patterns = set([sentence_to_short_seq(s) for s in train_sents])\n",
    "    train_patterns.discard(\"in\") # too general, remove this\n",
    "    test_patterns = [sentence_to_short_seq(s) for s in test_sents]\n",
    "    test_extracts = []\n",
    "\n",
    "    # iteratively get more patterns and entity pairs\n",
    "    for i in range(1, num_iter):\n",
    "        print(\"Number extractions at iteration\", str(i), \":\", str(len(test_extracts)))\n",
    "        print(\"Number patterns at iteration\", str(i), \":\", str(len(train_patterns)))\n",
    "        print(\"Number entpairs at iteration\", str(i), \":\", str(len(train_entpairs)))\n",
    "        # get more patterns and entity pairs\n",
    "        test_extracts_e, ext_test_patterns_e, ext_test_entpairs_e = search_for_patterns_by_entpairs(train_entpairs, test_patterns, test_entpairs, test_sents)\n",
    "        test_extracts_p, ext_test_patterns_p, ext_test_entpairs_p = search_for_entpairs_by_patterns(train_patterns, test_patterns, test_entpairs, test_sents)\n",
    "        # add them to the existing patterns and entity pairs for the next iteration\n",
    "        train_patterns.update(ext_test_patterns_p)\n",
    "        train_patterns.update(ext_test_patterns_e)\n",
    "        train_entpairs.extend(ext_test_entpairs_p)\n",
    "        train_entpairs.extend(ext_test_entpairs_e)\n",
    "        test_extracts.extend(test_extracts_p)\n",
    "        test_extracts.extend(test_extracts_e)\n",
    "\n",
    "    return test_extracts, test_entpairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_extracts, test_entpairs = ie.bootstrappingExtraction(training_patterns[:20], training_entpairs[:20], testing_patterns, testing_entpairs, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Problem: \n",
    "* with each iteration, the number of pattern, entity pairs and extractions increases\n",
    "* however, they are less correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_patterns = set(sentence_to_short_seq(s) for s in training_patterns[:20])\n",
    "test_patterns = set(sentence_to_short_seq(s) for s in test_extracts)\n",
    "\n",
    "# patterns that do not co-occur with first set of entity pairs\n",
    "for p in test_patterns:\n",
    "    if p not in train_patterns:\n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* One of the reasons is that the semantics of the pattern shifts (\"**semantic drift**\")\n",
    "    * here we try to find new patterns for 'method used for task'\n",
    "    * but because the instances share a similar context with other relations, the patterns and entity pairs iteratively move away from the 'method used in task' relation\n",
    "    * Another example: 'employee-at', 'student-at' -> many overlapping contexts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* One solution: confidence values for each entity pair and pattern\n",
    "    * E.g., we might want to avoid entity pairs or patterns which are too general and penalise them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "te_cnt = Counter()\n",
    "for te in test_extracts:\n",
    "    te_cnt[sentence_to_short_seq(te)] += 1\n",
    "print(te_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* Such a 'noisy' pattern is e.g. 'in': it matches many contexts that are not 'method used for task' \n",
    "* **Thought exercise**: \n",
    "    * how would a confidence weighting for patterns work here?\n",
    "    \n",
    "Enter answer: https://tinyurl.com/y3dxzjuz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Supervised Relation Extraction\n",
    "* Follow the supervised learning paradigm\n",
    "    * We have already seen for other structured prediction tasks\n",
    "* Scoring model \\\\(s_{\\params}(\\x,y)\\\\) is estimated based on training sentences $\\mathcal{X}$ and their labels $\\mathcal{Y}$\n",
    "* We can use range of different classifiers, e.g. a logistic regression model or an SVM\n",
    "* At testing time, the predict highest-scoring label for each testing instance, i.e. $$ \\y^* = \\argmax_{\\y\\in\\Ys} s(\\x,\\y) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Example\n",
    "* The training data consists again of patterns, entity pairs and labels\n",
    "* This time, the given labels for the training instances are 'method used for task' or 'NONE', i.e. we have positive and negative training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_sents, training_entpairs, training_labels = ie.readLabelledData()\n",
    "print(\"Manually labelled data set consists of\", training_labels.count(\"NONE\"), \n",
    "          \"negative training examples and\", training_labels.count(\"method used for task\"), \"positive training examples\\n\")\n",
    "list(zip(training_sents[:3], training_entpairs[:3], training_labels[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Feature extraction\n",
    "* Transform training and testing data to features \n",
    "* Typical features: shortest dependency path between two entities (see [parsing slides](dependency_parsing_slides.ipynb))\n",
    "* We assume again that entity pairs are already recognised\n",
    "\n",
    "* Example shown with sklearn's built-in feature extractor to transform sentences to n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def feat_transform(sents_train, sents_test):\n",
    "    cv = CountVectorizer()\n",
    "    cv.fit(sents_train)\n",
    "    print(cv.get_params())\n",
    "    features_train = cv.transform(sents_train)\n",
    "    features_test = cv.transform(sents_test)\n",
    "    return features_train, features_test, cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Define a model, here: sklearn, using one of their built-in classifiers and a prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def model_train(feats_train, labels):\n",
    "    model = LogisticRegression(penalty='l2', solver='liblinear')  # logistic regression model with l2 regularisation\n",
    "    model.fit(feats_train, labels) # fit the model to the transformed training data\n",
    "    return model\n",
    "\n",
    "def predict(model, features_test):\n",
    "    \"\"\"Find the most compatible output class\"\"\"\n",
    "    preds = model.predict(features_test) # this returns the predicted labels\n",
    "    #preds_prob = model.predict_proba(features_test)  # this returns probablities instead of labels\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Helper function for debugging that determines the most useful features learned by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_most_informative_features(vectorizer, clf, n=20):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        print(\"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Supervised relation extraction algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def supervised_extraction(train_sents, train_entpairs, train_labels, test_sents, test_entpairs):\n",
    "    \"\"\"\n",
    "    Given pos/neg training instances, train a logistic regression model with simple BOW features and predict labels on unseen test instances\n",
    "    Args:\n",
    "        train_sents: training sentences with arguments masked\n",
    "        train_entpairs: training entity pairs\n",
    "        train_labels: labels of training instances\n",
    "        test_sents: testing sentences with arguments masked\n",
    "        test_entpairs: testing entity pairs\n",
    "    Returns:\n",
    "        predictions for the testing sentences\n",
    "    \"\"\"\n",
    "\n",
    "    # convert training and testing sentences to short paths to obtain patterns\n",
    "    train_patterns = [sentence_to_short_seq(test_sent) for test_sent in train_sents]\n",
    "    test_patterns = [sentence_to_short_seq(test_sent) for test_sent in test_sents]\n",
    "\n",
    "    # extract features\n",
    "    features_train, features_test, cv = feat_transform(train_patterns, test_patterns)\n",
    "\n",
    "    # train model\n",
    "    model = model_train(features_train, train_labels)\n",
    "\n",
    "    # show most common features\n",
    "    show_most_informative_features(cv, model)\n",
    "\n",
    "    # get predictions\n",
    "    predictions = predict(model, features_test)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "testing_preds = supervised_extraction(training_sents, training_entpairs, training_labels, testing_patterns, testing_entpairs)\n",
    "list(zip(testing_preds, testing_patterns, testing_entpairs))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Model Inspection\n",
    "* Some the features are common words (i.e. 'stop words', such as 'is') and very broad\n",
    "* Others are very specific and thus might not appear very often\n",
    "* Typically these problems can be mitigated by using more involved features, e.g. based on syntax\n",
    "* Current model ignores entity pairs, only featurises the path between the entity pairs\n",
    "    * We will later examine a model that also takes entity pairs into account\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* Finally, the model requires manually annotated training data, which might not always be available\n",
    "* Next, we will look at a method that provides a solution for the latter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Distant Supervision\n",
    "* Supervised learning typically requires large amounts of hand-labelled training examples\n",
    "* It is **time-consuming and expensive** to manually label examples\n",
    "    * It is desirable to find ways of automatically or semi-automatically producing more training data\n",
    "    * We have already seen one example of this, bootstrapping\n",
    "* Downside of bootstrapping: **semantic drift** \n",
    "    * due to the iterative nature of finding good entity pairs and patterns\n",
    "* Alternative: distant supervision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* We still have a set of entity pairs $\\mathcal{E}$, their relation types $\\mathcal{R}$ and a set of sentences $\\mathcal{X}$ as an input\n",
    "    * but we do **not require pre-defined patterns**\n",
    "* Instead, entity pairs and relations are obtained from a **knowledge resource**, e.g. the [Wikidata knowledge base](https://www.wikidata.org), Yago or Freebase\n",
    "* Those are used to automatically label all sentences with relations\n",
    "* Afterwards: supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def distantly_supervised_labelling(kb_entpairs, unlab_sents, unlab_entpairs):\n",
    "    \"\"\"\n",
    "    Label instances using distant supervision assumption\n",
    "    Args:\n",
    "        kb_entpairs: entity pairs for a specific relation\n",
    "        unlab_sents: unlabelled sentences with entity pairs anonymised\n",
    "        unlab_entpairs: entity pairs which were anonymised in unlab_sents\n",
    "\n",
    "    Returns: pos_train_sents, pos_train_enpairs, neg_train_sents, neg_train_entpairs\n",
    "\n",
    "    \"\"\"\n",
    "    train_sents, train_entpairs, train_labels = [], [], []\n",
    "    for i, unlab_entpair in enumerate(unlab_entpairs):\n",
    "        # if the entity pair is a KB tuple, it is a positive example for that relation\n",
    "        if unlab_entpair in kb_entpairs:  \n",
    "            train_entpairs.append(unlab_entpair)\n",
    "            train_sents.append(unlab_sents[i])\n",
    "            train_labels.append(\"method used for task\")\n",
    "        else: # else, it is a negative example for that relation\n",
    "            train_entpairs.append(unlab_entpair)\n",
    "            train_sents.append(unlab_sents[i])\n",
    "            train_labels.append(\"NONE\")\n",
    "\n",
    "    return train_sents, train_entpairs, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def distantly_supervised_extraction(kb_entpairs, unlab_sents, unlab_entpairs, test_sents, test_entpairs):\n",
    "    # training_data <- Find training sentences with entity pairs\n",
    "    train_sents, train_entpairs, train_labels = distantly_supervised_labelling(kb_entpairs, unlab_sents, unlab_entpairs)\n",
    "    \n",
    "    print(\"Distantly supervised labelling results in\", train_labels.count(\"NONE\"), \n",
    "          \"negative training examples and\", train_labels.count(\"method used for task\"), \"positive training examples\")\n",
    "    \n",
    "    # training works the same as for supervised RE\n",
    "    return supervised_extraction(train_sents, train_entpairs, train_labels, test_sents, test_entpairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kb_entpairs, unlab_sents, unlab_entpairs = ie.readDataForDistantSupervision()\n",
    "#print(len(kb_entpairs), \"'KB' entity pairs for relation 'method used for task' :\", kb_entpairs[0:5])\n",
    "#print(len(unlab_entpairs), 'all entity pairs')\n",
    "testing_preds = distantly_supervised_extraction(kb_entpairs, unlab_sents, unlab_entpairs, testing_patterns, testing_entpairs)\n",
    "list(zip(testing_preds, testing_patterns, testing_entpairs))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* Here, results are the same as for supervised relation extraction, because the distant supervision heuristic identified the same positive and negative training examples as in the manually labelled dataset\n",
    "* In practice, the distant supervision heuristic typically leads to noisy training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* **Overlapping relations**\n",
    "    * For instance, 'prof-at' entails 'employee-of' and there are some overlapping entity pairs between the relations 'employee-of' and 'student-at'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* **Ambiguous entities**\n",
    "    * e.g. 'EM' has many possible meanings, only one of which is 'Expectation Maximisation', see [the Wikipedia disambiguation page for the acronym](https://en.wikipedia.org/wiki/EM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* **Mention vs. type annotations**\n",
    "    * Not every sentence a positive entity pair appears in actually expresses that relation\n",
    "    * e.g. 'lives-in', 'works-in', etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Universal Schema\n",
    "* For pattern-based and bootstrapping, we looked for simplified paths between entity pairs $\\mathcal{E}$ expressing a relation $\\mathcal{R}$ defined beforehand\n",
    "    * This **restricts the relation extraction problem to known relation types** $\\mathcal{R}$\n",
    "    * To overcome that limitation, we could have defined new relation types for certain simplified relation types on the spot\n",
    "    * Here: more principled solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Universal Schema\n",
    "* Goal: overcome limitation of having to pre-define relations, within the supervised learning paradigm\n",
    "* This is possible by viewing relation paths **as relations themselves**\n",
    "* Simplified paths between entity pairs and relations defined in knowledge base are **no longer considered separately**\n",
    "    * instead they are **modelled in the same space**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The space of entity pairs and relations is defined by a matrix:\n",
    "\n",
    "|  | demonstrates XXXXX for XXXXXX | XXXXX is capable of XXXXXX | an XXXXX model is employed for XXXXX | XXXXX decreases the XXXXX | method is used for task |\n",
    "| ------ | ----------- |\n",
    "| 'text mining', 'building domain ontology' | 1 |  |  |  | 1 |\n",
    "| 'ensemble classifier', 'detection of construction materials' |  |  | 1 |  | 1 |\n",
    "| 'data mining', 'characterization of wireless systems performance'|  | 1 |  |  | ? |\n",
    "| 'frequency domain', 'computational cost' |  |  |  | 1 | ? |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* 'method is used for task' is a relation defined by a KB schema\n",
    "* The other relations are surface pattern relations\n",
    "* Where an entity pair and a KB relation or surface pattern relation co-occur, this is signified by a '1'\n",
    "* For some of the entities and surface pairs, a label for 'method used for task' is available, whereas for others, it is not (signified by the '?')\n",
    "* We can use the same data as for supervised RE, as merely the data representation and model are different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model: Neural Matrix Factorisation for Recommender Systems\n",
    "\n",
    "<img src=\"dl-applications-figures/neural_mf.png\" width=800/> \n",
    "\n",
    "Source: https://arxiv.org/abs/1707.07435"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* Neural Matrix Factorisation model for Recommender Systems is adapted for relation extraction\n",
    "   * Users -> relations\n",
    "   * Items -> entity pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* **Prediction task**: learn to fill in the empty cells in the matrix\n",
    "    * i.e. turn the '?'s into 0/1 predictions for predicting the 'method for task' relation\n",
    "    * estimate, for a relation $\\mathcal{r}$ such as 'method is used for task' and an unseen entity pair such as $\\mathcal{e}$, e.g. ('frequency domain', 'computational cost'), what the probability $\\mathcal{p(y_{r,e} = 1)}$ is.\n",
    "* **Training objective**: \n",
    "    * learning to distinguish between entity pairs and relations which co-occur in our training data (positive instances) and entity pairs and relations which are not known to co-occur (negative instances, i.e. the empty cells)\n",
    "    * logistic loss, or ranking objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* **Features representations**:\n",
    "    * embeddings for entity pairs and relations, see [word representation](chapters/dl-representations.ipynb) and [RNN slides](chapters/rnn_slides_ucph.ipynb)\n",
    "* **Model**:\n",
    "    * dot product between entity and relation embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* **Training instance**: consists of a surface pattern or KB relation $\\mathcal{r_{pos}}$ and an entity pair  $\\mathcal{e_{pos}}$ the relation co-occurs with, as well as a relation $\\mathcal{r_{neg}}$ and a entity pair $\\mathcal{e_{neg}}$ that do not co-occur in the training data\n",
    "* **Positive relations and entity pairs**: directly taken from the annotated data\n",
    "* **Negative entity pairs and relations**: *sampled randomly* from data points which are represented by the empty cell in the matrix above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data reading\n",
    "training_sents, training_entpairs, training_labels = ie.readLabelledData()\n",
    "\n",
    "# split positive and negative training data\n",
    "pos_train_ids, neg_train_ids = ie.split_labels_pos_neg(training_labels + training_labels)\n",
    "\n",
    "training_toks_pos = [t.split(\" \") for i, t in enumerate(training_sents + training_labels) if i in pos_train_ids]\n",
    "training_toks_neg = [t.split(\" \") for i, t in enumerate(training_sents + training_labels) if i in neg_train_ids]\n",
    "\n",
    "training_ent_toks_pos = [\" || \".join(t).split(\" \") for i, t in enumerate(training_entpairs + training_entpairs) if i in pos_train_ids]\n",
    "training_ent_toks_neg = [\" || \".join(t).split(\" \") for i, t in enumerate(training_entpairs + training_entpairs) if i in neg_train_ids]\n",
    "testing_ent_toks = [\" || \".join(t).split(\" \") for t in testing_entpairs]\n",
    "\n",
    "# print length statistics\n",
    "lens_rel = [len(s) for s in training_toks_pos + training_toks_neg]\n",
    "lens_ents = [len(s) for s in training_ent_toks_pos + training_ent_toks_neg + testing_ent_toks]\n",
    "print(\"Max relation length:\", max(lens_rel))\n",
    "print(\"Max entity pair length:\", max(lens_ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# vectorise data (assign IDs to words)\n",
    "count_rels, dictionary_rels, reverse_dictionary_rels = ie.build_dataset(\n",
    "        [token for senttoks in training_toks_pos + training_toks_neg for token in senttoks])\n",
    "\n",
    "count_ents, dictionary_ents, reverse_dictionary_ents = ie.build_dataset(\n",
    "        [token for senttoks in training_ent_toks_pos + training_ent_toks_neg for token in senttoks])\n",
    "\n",
    "print(reverse_dictionary_rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# transform sentences to IDs, pad vectors for each sentence so they have same length\n",
    "rels_train_pos = [ie.transform_dict(dictionary_rels, senttoks, max(lens_rel)) for senttoks in training_toks_pos]\n",
    "rels_train_neg = [ie.transform_dict(dictionary_rels, senttoks, max(lens_rel)) for senttoks in training_toks_neg]\n",
    "ents_train_pos = [ie.transform_dict(dictionary_ents, senttoks, max(lens_ents)) for senttoks in training_ent_toks_pos]\n",
    "ents_train_neg = [ie.transform_dict(dictionary_ents, senttoks, max(lens_ents)) for senttoks in training_ent_toks_neg]\n",
    "\n",
    "print(rels_train_pos[0], \"\\n\", rels_train_pos[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Negatively sample some entity pairs for training. Here we have some manually labelled neg ones, so we can sample from them.\n",
    "ents_train_neg_samp = [random.choice(ents_train_neg) for _ in rels_train_neg]\n",
    "    \n",
    "ents_test_pos = [ie.transform_dict(dictionary_ents, senttoks, max(lens_ents)) for senttoks in testing_ent_toks]\n",
    "# Sample those test entity pairs from the training ones as for those we have neg annotations\n",
    "ents_test_neg_samp = [random.choice(ents_train_neg) for _ in ents_test_pos]  \n",
    "\n",
    "vocab_size_rels = len(dictionary_rels)\n",
    "vocab_size_ents = len(dictionary_ents) \n",
    "\n",
    "# for testing, we want to check if each unlabelled instance expresses the given relation \"method for task\"\n",
    "rels_test_pos = [ie.transform_dict(dictionary_rels, training_toks_pos[-1], max(lens_rel)) for _ in testing_patterns]\n",
    "rels_test_neg_samp = [random.choice(rels_train_neg) for _ in rels_test_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = ie.vectorise_data(training_sents, training_entpairs, training_labels, testing_patterns, testing_entpairs)\n",
    "\n",
    "rels_train_pos, rels_train_neg, ents_train_pos, ents_train_neg_samp, rels_test_pos, rels_test_neg_samp, \\\n",
    "    ents_test_pos, ents_test_neg_samp, vocab_size_rels, vocab_size_ents, max_lens_rel, max_lens_ents, \\\n",
    "    dictionary_rels_rev, dictionary_ents_rev = data\n",
    "  \n",
    "# setting hyper-parameters\n",
    "batch_size = 4\n",
    "repr_dim = 30 # dimensionality of relation and entity pair vectors\n",
    "learning_rate = 0.001\n",
    "max_epochs = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model_f_reader(max_rel_seq_length, max_cand_seq_length, repr_dim, vocab_size_rels, vocab_size_cands):\n",
    "    \"\"\"\n",
    "    Create a Model F Universal Schema reader (Tensorflow graph).\n",
    "    Args:\n",
    "        max_rel_seq_length: maximum sentence sequence length\n",
    "        max_cand_seq_length: maximum candidate sequence length\n",
    "        repr_dim: dimensionality of vectors\n",
    "        vocab_size_rels: size of relation vocabulary\n",
    "        vocab_size_cands: size of candidate vocabulary\n",
    "    Returns:\n",
    "        dotprod_pos: dot product between positive entity pairs and relations\n",
    "        dotprod_neg: dot product between negative entity pairs and relations\n",
    "        diff_dotprod: difference in dot product of positive and negative instances, used for BPR loss (optional)\n",
    "        [relations_pos, relations_neg, ents_pos, ents_neg]: placeholders, fed in during training for each batch\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Placeholders (empty Tensorflow variables) for positive and negative relations and entity pairs\n",
    "# In each training epoch, for each batch, those will be set through mini batching\n",
    "\n",
    "relations_pos = tf.placeholder(tf.int32, [None, max_lens_rel], name='relations_pos')  # [batch_size, max_rel_seq_len]\n",
    "relations_neg = tf.placeholder(tf.int32, [None, max_lens_rel], name='relations_neg')  # [batch_size, max_rel_seq_len]\n",
    "\n",
    "ents_pos = tf.placeholder(tf.int32, [None, max_lens_ents], name=\"ents_pos\") # [batch_size, max_ent_seq_len]\n",
    "ents_neg = tf.placeholder(tf.int32, [None, max_lens_ents], name=\"ents_neg\") # [batch_size, max_ent_seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating latent representations of relations and entity pairs\n",
    "# latent feature representation of all relations, which are initialised randomly\n",
    "relation_embeddings = tf.Variable(tf.random_uniform([vocab_size_rels, repr_dim], -0.1, 0.1, dtype=tf.float32),\n",
    "                                   name='rel_emb', trainable=True)\n",
    "\n",
    "# latent feature representation of all entity pairs, which are initialised randomly\n",
    "ent_embeddings = tf.Variable(tf.random_uniform([vocab_size_ents, repr_dim], -0.1, 0.1, dtype=tf.float32),\n",
    "                                      name='cand_emb', trainable=True)\n",
    "\n",
    "# look up latent feature representation for relations and entities in current batch\n",
    "rel_encodings_pos = tf.nn.embedding_lookup(relation_embeddings, relations_pos)\n",
    "rel_encodings_neg = tf.nn.embedding_lookup(relation_embeddings, relations_neg)\n",
    "\n",
    "ent_encodings_pos = tf.nn.embedding_lookup(ent_embeddings, ents_pos)\n",
    "ent_encodings_neg = tf.nn.embedding_lookup(ent_embeddings, ents_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# our feature representation here is a vector for each word in a relation or entity \n",
    "# because our training data is so small\n",
    "# we therefore take the sum of those vectors to get a representation of each relation or entity pair\n",
    "rel_encodings_pos = tf.reduce_sum(rel_encodings_pos, 1)  # [batch_size, num_rel_toks, repr_dim]\n",
    "rel_encodings_neg = tf.reduce_sum(rel_encodings_neg, 1)  # [batch_size, num_rel_toks, repr_dim]\n",
    "\n",
    "ent_encodings_pos = tf.reduce_sum(ent_encodings_pos, 1)  # [batch_size, num_ent_toks, repr_dim]\n",
    "ent_encodings_neg = tf.reduce_sum(ent_encodings_neg, 1)  # [batch_size, num_ent_toks, repr_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# measuring compatibility between positive entity pairs and relations\n",
    "# used for ranking test data\n",
    "dotprod_pos = tf.reduce_sum(tf.multiply(ent_encodings_pos, rel_encodings_pos), 1)\n",
    "\n",
    "# measuring compatibility between negative entity pairs and relations\n",
    "dotprod_neg = tf.reduce_sum(tf.multiply(ent_encodings_neg, rel_encodings_neg), 1)\n",
    "\n",
    "# difference in dot product of positive and negative instances\n",
    "# used for BPR loss (ranking loss)\n",
    "diff_dotprod = tf.reduce_sum(tf.multiply(ent_encodings_pos, rel_encodings_pos) - tf.multiply(ent_encodings_neg, rel_encodings_neg), 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To train this model, we define a loss, which tries to maximise the distance between the positive and negative instances. One possibility of this is the logistic loss.\n",
    "\n",
    "$\\mathcal{\\sum -  \\log(v_{e_{pos}} * a_{r_{pos}})} + {\\sum \\log(v_{e_{neg}} * a_{r_{neg}})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now that we have read in the data, vectorised it and created the universal schema relation extraction model, let's start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create the model / Tensorflow computation graph\n",
    "dotprod_pos, dotprod_neg, diff_dotprod, placeholders = ie.create_model_f_reader(max_lens_rel, max_lens_ents, repr_dim, vocab_size_rels,\n",
    "                          vocab_size_ents)\n",
    "\n",
    "# logistic loss\n",
    "loss = tf.reduce_sum(tf.nn.softplus(-dotprod_pos)+tf.nn.softplus(dotprod_neg))\n",
    "\n",
    "# alternative: BPR loss\n",
    "#loss = tf.reduce_sum(tf.nn.softplus(diff_dotprod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = [np.asarray(rels_train_pos), np.asarray(rels_train_neg), np.asarray(ents_train_pos), np.asarray(ents_train_neg_samp)]\n",
    "data_test = [np.asarray(rels_test_pos), np.asarray(rels_test_neg_samp), np.asarray(ents_test_pos), np.asarray(ents_test_neg_samp)]\n",
    "\n",
    "# define an optimiser. Here, we use the Adam optimiser\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    \n",
    "# training with mini-batches\n",
    "batcher = tfutil.BatchBucketSampler(data, batch_size)\n",
    "batcher_test = tfutil.BatchBucketSampler(data_test, 1, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    trainer = tfutil.Trainer(optimizer, max_epochs)\n",
    "    trainer(batcher=batcher, placeholders=placeholders, loss=loss, session=sess)\n",
    "\n",
    "    # we obtain test scores\n",
    "    test_scores = trainer.test(batcher=batcher_test, placeholders=placeholders, model=tf.nn.sigmoid(dotprod_pos), session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# show predictions\n",
    "ents_test = [ie.reverse_dict_lookup(dictionary_ents_rev, e) for e in ents_test_pos]\n",
    "rels_test = [ie.reverse_dict_lookup(dictionary_rels_rev, r) for r in rels_test_pos]\n",
    "testresults = sorted(zip(test_scores, ents_test, rels_test), key=lambda t: t[0], reverse=True)  # sort for decreasing score\n",
    "\n",
    "print(\"\\nTest predictions by decreasing probability:\")\n",
    "for score, tup, rel in testresults[:10]:\n",
    "    print('%f\\t%s\\tREL\\t%s' % (score, \" \".join(tup), \" \".join(rel)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Test prediction probabilities are obtained by scoring each test instances with:\n",
    "\n",
    "$\\mathcal{ \\sigma  ( v_{e} \\cdot a_{r} )}$\n",
    "\n",
    "* Note that as input for the latent feature representation, we discarded words that only appeared twice\n",
    "    * Hence, for those words we did not learn a representation, denoted here by 'UNK'\n",
    "* This is also typically done for other feature representations, as if we only see a feature once, it is difficult to learn weights for it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Thought Exercises**: \n",
    "* The scores shown here are for the relation 'method used for task'. However, we could also use our model to score the compatibility of entity pairs with other relations, e.g. 'demonstrates XXXXX for XXXXXX'. How could this be done here?\n",
    "* How could we get around the problem of unseen words, as described above?\n",
    "* What other possible problems can you see with the above formulation of universal schema relation extraction?\n",
    "* What possible problems can you see with using latent word representations?\n",
    "\n",
    "Enter answer: https://tinyurl.com/yytql7wh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Summary\n",
    "\n",
    "Various relation extraction techniques:\n",
    "* Pattern-based extraction\n",
    "* Bootstrapping\n",
    "* Supervised\n",
    "* Distantly supervised extraction\n",
    "* Universal schema\n",
    "\n",
    "Features often a mix of \n",
    "* Syntax-based (relation path)\n",
    "* Representation learning based (word/sentence embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Background Material\n",
    "\n",
    "* Jurafky, Dan and Martin, James H. (2016). Speech and Language Processing, Chapter 18 (Information Extraction): https://web.stanford.edu/~jurafsky/slp3/18.pdf\n",
    "\n",
    "* Riedel, Sebastian and Yao, Limin and McCallum, Andrew and Marlin, Benjamin M. (2013). Relation extraction with Matrix Factorization and Universal Schemas. Proceedings of NAACL.  http://www.aclweb.org/anthology/N13-1008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Further Reading\n",
    "\n",
    "* Quan Wang, Zhendong Mao, Bin Wang, and Li Guo (2017). Knowledge Graph Embedding: A Survey of Approaches and Applications. https://persagen.com/files/misc/Wang2017Knowledge.pdf\n",
    "    * Have a look at this for more scoring functions for universal schema relation extraction\n",
    "* Shantanu Kumar (2017). A Survey of Deep Learning Methods for Relation Extraction. https://arxiv.org/pdf/1705.03645.pdf\n",
    "* Alex Ratner, Stephen Bach, Paroma Varma, Chris Ré (2018). Weak Supervision: The New Programming Paradigm for Machine Learning. https://dawn.cs.stanford.edu/2017/07/16/weak-supervision/\n",
    "    * Have a look at this for details on weak supervision and pointers to methods for learning with limited labelled data\n",
    "* Awesome relation extraction, curated list of resources on relation extraction. https://github.com/roomylee/awesome-relation-extraction"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}