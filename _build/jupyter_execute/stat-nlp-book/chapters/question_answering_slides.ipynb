{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "  function code_toggle() {\n",
       "    if (code_shown){\n",
       "      $('div.input').hide('500');\n",
       "      $('#toggleButton').val('Show Code')\n",
       "    } else {\n",
       "      $('div.input').show('500');\n",
       "      $('#toggleButton').val('Hide Code')\n",
       "    }\n",
       "    code_shown = !code_shown\n",
       "  }\n",
       "\n",
       "  $( document ).ready(function(){\n",
       "    code_shown=false;\n",
       "    $('div.input').hide()\n",
       "  });\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>\n",
       "<style>\n",
       ".rendered_html td {\n",
       "    font-size: xx-large;\n",
       "    text-align: left; !important\n",
       "}\n",
       ".rendered_html th {\n",
       "    font-size: xx-large;\n",
       "    text-align: left; !important\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>\n",
    "<style>\n",
    ".rendered_html td {\n",
    "    font-size: xx-large;\n",
    "    text-align: left; !important\n",
    "}\n",
    ".rendered_html th {\n",
    "    font-size: xx-large;\n",
    "    text-align: left; !important\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../statnlpbook/\")\n",
    "\n",
    "#util.execute_notebook('relation_extraction.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<!---\n",
    "Latex Macros\n",
    "-->\n",
    "$$\n",
    "\\newcommand{\\Xs}{\\mathcal{X}}\n",
    "\\newcommand{\\Ys}{\\mathcal{Y}}\n",
    "\\newcommand{\\y}{\\mathbf{y}}\n",
    "\\newcommand{\\balpha}{\\boldsymbol{\\alpha}}\n",
    "\\newcommand{\\bbeta}{\\boldsymbol{\\beta}}\n",
    "\\newcommand{\\aligns}{\\mathbf{a}}\n",
    "\\newcommand{\\align}{a}\n",
    "\\newcommand{\\source}{\\mathbf{s}}\n",
    "\\newcommand{\\target}{\\mathbf{t}}\n",
    "\\newcommand{\\ssource}{s}\n",
    "\\newcommand{\\starget}{t}\n",
    "\\newcommand{\\repr}{\\mathbf{f}}\n",
    "\\newcommand{\\repry}{\\mathbf{g}}\n",
    "\\newcommand{\\x}{\\mathbf{x}}\n",
    "\\newcommand{\\prob}{p}\n",
    "\\newcommand{\\a}{\\alpha}\n",
    "\\newcommand{\\b}{\\beta}\n",
    "\\newcommand{\\vocab}{V}\n",
    "\\newcommand{\\params}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\param}{\\theta}\n",
    "\\DeclareMathOperator{\\perplexity}{PP}\n",
    "\\DeclareMathOperator{\\argmax}{argmax}\n",
    "\\DeclareMathOperator{\\argmin}{argmin}\n",
    "\\newcommand{\\train}{\\mathcal{D}}\n",
    "\\newcommand{\\counts}[2]{\\#_{#1}(#2) }\n",
    "\\newcommand{\\length}[1]{\\text{length}(#1) }\n",
    "\\newcommand{\\indi}{\\mathbb{I}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tikzmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Schedule\n",
    "\n",
    "* Question answering (10 min.)\n",
    "* Machine reading comprehension (20 min.)\n",
    "* Executable semantic parsing (5 min.)\n",
    "* Exercise: IR- vs. KB-QA (15 min.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Question:\n",
    "\n",
    ">Which university did Turing go to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Answer:\n",
    "\n",
    ">Princeton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[Passage](https://history-computer.com/people/alan-turing-complete-biography/):\n",
    "\n",
    ">Alan Turing graduated from Princeton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Knowledge base:\n",
    "\n",
    "https://www.wikidata.org/wiki/Q7251"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Flavours of Question answering (QA)\n",
    "\n",
    "* Factoid QA\n",
    "    * Information retrieval (IR)-based QA (by **machine reading comprehension**) on **unstructured** data (text)\n",
    "    * Knowledge-based QA (by **semantic parsing** to logical form/SQL/SPARQL) on **structured** data (DB/KB)\n",
    "* Non-factoid QA\n",
    "    * Math problems ![math](https://d3i71xaburhd42.cloudfront.net/fb1c90806fc5ec72987f58110aa255edbce6620d/1-Figure1-1.png)\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Lu et al., 2021](https://aclanthology.org/2021.acl-long.528/))\n",
    "</div>\n",
    "\n",
    "    * \"How\" questions\n",
    "> How do I delete my Instagram account?\n",
    "\n",
    "    * \"Why\" questions\n",
    "> Why is the sky blue?\n",
    "    * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### QA datasets\n",
    "\n",
    "* SQuAD ([Rajpurkar et al., 2016](https://www.aclweb.org/anthology/D16-1264.pdf), [Rajpurkar & Jia et al., 2018](https://www.aclweb.org/anthology/P18-2124.pdf))\n",
    "* QuAC ([Choi et al., 2018](https://www.aclweb.org/anthology/D18-1241.pdf))\n",
    "* CoQA ([Reddy et al., 2019](https://www.aclweb.org/anthology/Q19-1016.pdf))\n",
    "* Natural Questions ([Kwiatkowski et al., 2019](https://www.aclweb.org/anthology/Q19-1026.pdf))\n",
    "* TyDI-QA ([Clark et al., 2020](https://www.aclweb.org/anthology/2020.tacl-1.30.pdf))\n",
    "* ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Information retrieval (IR)-based QA\n",
    "\n",
    "General approach:\n",
    "1. Retrieve relevant **passage**(s)\n",
    "2. Machine reading comprehension: extract the **answer**, which can be\n",
    "    * A text span from the passage\n",
    "    * Yes/no\n",
    "    * `NULL` (unanswerable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Machine reading comprehension (MRC)\n",
    "\n",
    "* Input: (Passage, Question)\n",
    "* Output: Answer span\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://rajpurkar.github.io/mlx/qa-and-squad/example-squad.png\" width=\"70%\">\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Rajpurkar et al., 2016](https://www.aclweb.org/anthology/D16-1264.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### MRC demo\n",
    "\n",
    "### https://demo.allennlp.org/reading-comprehension/MjMzNTgxOA==\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### MRC modeling\n",
    "\n",
    "How to model span selection?\n",
    "\n",
    "* As sequence labeling (for each token, is it part of the answer?)\n",
    "\n",
    "What may be the possible tags for each token?\n",
    "\n",
    "* As span selection (find start and end of the answer span)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### MRC evaluation\n",
    "\n",
    "Test questions have $k$ gold answers by different human annotators ($k=3$ for SQuAD and TyDI-QA, $k=5$ for NQ)\n",
    "\n",
    "Metrics for binary (yes/no) QA:\n",
    "* **Accuracy**\n",
    "* **F1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Metrics for ranking:\n",
    "* **MRR** (mean reciprocal rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Metrics for span selection:\n",
    "* **Exact match** (EM): text is exactly any of the $k$\n",
    "* Word **F1** (see [sequence labeling slides](sequence_labeling_slides.ipynb)) averaged over the $k$ gold answers\n",
    "    * Often ignoring punctuation and articles, i.e., `a, an, the`\n",
    "    * As bag-of-words, not exact positions (because the same answer may appear multiple times)\n",
    "    * Macro-averaged: calculate F1 for each question and average the F1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SQuAD\n",
    "\n",
    "<center>\n",
    "    <a href=\"slides/cs224n-2020-lecture10-QA.pdf\"><img src=\"qa_figures/squad.png\"></a>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Rajpurkar et al., 2016](https://www.aclweb.org/anthology/D16-1264.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### MRC Models\n",
    "\n",
    "![model](https://d3i71xaburhd42.cloudfront.net/1b78ce27180c324f3831f5395a2fdf738e143e74/2-Figure1-1.png)\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from <a href=\"https://aclanthology.org/2020.aacl-srw.21/\">Li et al., 2020</a>)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### MRC with BERT\n",
    "\n",
    "<center>\n",
    "    <img src=\"http://jalammar.github.io/images/bert-tasks.png\" width=60%/>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from <a href=\"https://www.aclweb.org/anthology/N19-1423.pdf\">Devlin et al., 2019</a>)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Knowledge-based (KB) question answering\n",
    "\n",
    "Information is already organized in tables, databases and knowledge bases!\n",
    "\n",
    "1. (Executable) **semantic parsing**: translate natural language question to SQL/SPARQL/logical form **program** (query).\n",
    "2. **Execute** the program on a database/knowledge-base and return the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Knowledge Bases\n",
    "\n",
    "![wikidata](https://upload.wikimedia.org/wikipedia/commons/thumb/6/66/Wikidata-logo-en.svg/500px-Wikidata-logo-en.svg.png)\n",
    "\n",
    "[Which university did Turing go to?](https://query.wikidata.org/#select%20distinct%20%3Fitem%20%3FitemLabel%20where%20%7B%0A%20%20%20%20%3Fitem%20wdt%3AP31%20wd%3AQ15936437.%0A%20%20%20%20wd%3AQ7251%20wdt%3AP69%20%3Fitem.%0A%20%20%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22en%22%20%7D%0A%7D%0AORDER%20BY%20DESC%28%3Fsitelinks%29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Executable semantic parsing to SPARQL\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://d3i71xaburhd42.cloudfront.net/8b65582bcb84b30393c67a2bae71a9e84f45e87c/4-Figure1-1.png\" width=\"100%\">\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Keysers et al., 2020](https://arxiv.org/pdf/1912.09713.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Executable semantic parsing to SQL\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://d3i71xaburhd42.cloudfront.net/37882abaec01eba1bf5bda8a36c904aaea0d5642/6-Table1-1.png\" width=\"80%\">\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Oren et al., 2020](https://arxiv.org/pdf/2010.05647.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Executable semantic parsing to SQL\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://d3i71xaburhd42.cloudfront.net/23474a845ea4b67f38bde7c7f1c4c1bdba22c50c/1-Figure1-1.png\" width=\"80%\">\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Finegan-Dollak et al., 2018](https://www.aclweb.org/anthology/P18-1033.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Executable semantic parsing to logical form\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://d3i71xaburhd42.cloudfront.net/b29447ba499507a259ae9d8f685d60cc1597d7d3/1-Figure1-1.png\" width=\"50%\">\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Berant et al., 2013](https://www.aclweb.org/anthology/D13-1160.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Why read when you can query?\n",
    "\n",
    "### https://ucph.padlet.org/dh/qa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "* Relation extraction can be cast as question answering (and vice versa)\n",
    "* Information retrieval-based question answering require reading comprehension\n",
    "* Knowledge-based question answering requires semantic parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Background Material\n",
    "\n",
    "* Question Answering. Blog post by Vered Shwartz: http://veredshwartz.blogspot.com/2016/11/question-answering.html\n",
    "* Jurafky, Dan and Martin, James H. (2016). Speech and Language Processing, Chapter 25 (Question Answering): https://web.stanford.edu/~jurafsky/slp3/25.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Further Reading\n",
    "\n",
    "* Conversational QA: https://abbanmustafa.github.io/slides-deck-1\n",
    "* Measuring Compositional Generalization. https://ai.googleblog.com/2020/03/measuring-compositional-generalization.html\n",
    "* Multilingual Compositional Wikidata Questions. https://arxiv.org/abs/2108.03509"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}