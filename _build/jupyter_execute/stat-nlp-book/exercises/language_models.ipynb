{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model Exercises\n",
    "In these exercises you will extend and develop language models. We will use the code from the notes, but within a python package [`lm`](http://localhost:8888/edit/statnlpbook/lm.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 1</font>: Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-21T16:59:18.569772",
     "start_time": "2016-10-21T16:59:18.552156"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import sys, os\n",
    "_snlp_book_dir = \"..\"\n",
    "sys.path.append(_snlp_book_dir) \n",
    "from statnlpbook.lm import *\n",
    "from statnlpbook.ohhla import *\n",
    "# %cd .. \n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 6.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "Latex Macros\n",
    "-->\n",
    "$$\n",
    "\\newcommand{\\prob}{p}\n",
    "\\newcommand{\\vocab}{V}\n",
    "\\newcommand{\\params}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\param}{\\theta}\n",
    "\\DeclareMathOperator{\\perplexity}{PP}\n",
    "\\DeclareMathOperator{\\argmax}{argmax}\n",
    "\\newcommand{\\train}{\\mathcal{D}}\n",
    "\\newcommand{\\counts}[2]{\\#_{#1}(#2) }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 2</font>: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-21T16:59:18.613748",
     "start_time": "2016-10-21T16:59:18.575886"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "docs = load_all_songs(\"../data/ohhla/train/www.ohhla.com/anonymous/j_live/\")\n",
    "assert len(docs) == 50, \"Your ohhla corpus is corrupted, please download it again!\"\n",
    "trainDocs, testDocs = docs[:len(docs)//2], docs[len(docs)//2:] \n",
    "train = words(trainDocs)\n",
    "test = words(testDocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 1</font>: Optimal Pseudo Count \n",
    "\n",
    "Plot the perplexity for laplace smoothing on the given data as a function of alpha in the interval [0.001, 0.1] in steps by 0.001. Is it fair to assume that this is a convex function? Write a method that finds the optimal pseudo count `alpha` number for [laplace smoothing](https://github.com/uclmr/stat-nlp-book/blob/python/statnlpbook/lm.py#L180) for the given data up to some predefined numerical precision `epsilon` under the assumption that the perplexity is a convex function of alpha. How often did you have to call `perplexity` to find the optimum?\n",
    "\n",
    "Tips:\n",
    "<font color='white'>\n",
    "You don't need 1st or 2nd order derivatives in this case, only the gradient descent direction. Think about recursively slicing up the problem.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-21T16:59:19.151308",
     "start_time": "2016-10-21T16:59:18.615252"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAFlCAYAAACjjD/AAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAASoUlEQVR4nO3db4yld3nf4e9db3EgqGAbQ8BLuk5wVS1N2lQTu1WTFvHHfyqRRY1fGFRl1VK5UusXaUQbU6oanKgClNZRFdrKCpFcXtROLUXZiLYrY4paoZR41iEkS+J4MSS2ccJiW0QOKq7J3RfzUE2ms9rFZ3bv2Znrko72PM/zmzP36KeZ/ficM+vq7gAAcGH9mekBAAD2IxEGADBAhAEADBBhAAADRBgAwAARBgAw4MD0AC/Gq171qj506ND0GAAAZ3XixImvdveVW89flBF26NChrK+vT48BAHBWVfV72533ciQAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAzYkQirqhur6pGqOlVVt29z/dKqum+5/pmqOrTl+ndX1XNV9Z6dmAcAYLdbOcKq6pIkH0lyU5LDSd5ZVYe3LHt3kme7+w1J7kryoS3X/02S/7rqLAAAF4udeCbs2iSnuvux7n4+yb1JjmxZcyTJPcv9+5O8paoqSarqHUm+mOTkDswCAHBR2IkIuyrJ45uOn1jObbumu19I8rUkV1TVy5P8ZJIPnO2TVNWtVbVeVeunT5/egbEBAOZMvzH//Unu6u7nzrawu+/u7rXuXrvyyivP/2QAAOfRgR14jCeTvH7T8cHl3HZrnqiqA0lekeTpJNclubmqPpzklUn+pKr+d3f/3A7MBQCwa+1EhD2U5JqqujobsXVLkndtWXMsydEkv5rk5iSf7O5O8sPfWlBV70/ynAADAPaDlSOsu1+oqtuSHE9ySZJf6O6TVXVnkvXuPpbko0k+VlWnkjyTjVADANi3auMJqYvL2tpar6+vT48BAHBWVXWiu9e2np9+Yz4AwL4kwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABuxIhFXVjVX1SFWdqqrbt7l+aVXdt1z/TFUdWs6/rapOVNVvLn++eSfmAQDY7VaOsKq6JMlHktyU5HCSd1bV4S3L3p3k2e5+Q5K7knxoOf/VJG/v7u9LcjTJx1adBwDgYrATz4Rdm+RUdz/W3c8nuTfJkS1rjiS5Z7l/f5K3VFV1969395eX8yeTvLSqLt2BmQAAdrWdiLCrkjy+6fiJ5dy2a7r7hSRfS3LFljU/muTh7v7Gdp+kqm6tqvWqWj99+vQOjA0AMGdXvDG/qt6YjZco/+GZ1nT33d291t1rV1555YUbDgDgPNiJCHsyyes3HR9czm27pqoOJHlFkqeX44NJfinJj3X3F3ZgHgCAXW8nIuyhJNdU1dVV9ZIktyQ5tmXNsWy88T5Jbk7yye7uqnplko8nub27P70DswAAXBRWjrDlPV63JTme5LeT/GJ3n6yqO6vqR5ZlH01yRVWdSvITSb71z1jcluQNSf5lVX12ub161ZkAAHa76u7pGb5ta2trvb6+Pj0GAMBZVdWJ7l7ben5XvDEfAGC/EWEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAAN2JMKq6saqeqSqTlXV7dtcv7Sq7luuf6aqDm269t7l/CNVdcNOzAMAsNutHGFVdUmSjyS5KcnhJO+sqsNblr07ybPd/YYkdyX50PKxh5PckuSNSW5M8u+WxwMA2NN24pmwa5Oc6u7Huvv5JPcmObJlzZEk9yz370/ylqqq5fy93f2N7v5iklPL4wEA7GkHduAxrkry+KbjJ5Jcd6Y13f1CVX0tyRXL+f+15WOv2oGZVvKBXzmZz3/5j6bHAADOo8Ov+3O54+1vHPv8F80b86vq1qpar6r106dPT48DALCSnXgm7Mkkr990fHA5t92aJ6rqQJJXJHn6HD82SdLddye5O0nW1tZ6B+Y+o8kqBgD2h514JuyhJNdU1dVV9ZJsvNH+2JY1x5IcXe7fnOST3d3L+VuW3568Osk1SX5tB2YCANjVVn4mbHmP121Jjie5JMkvdPfJqrozyXp3H0vy0SQfq6pTSZ7JRqhlWfeLST6f5IUk/7i7v7nqTAAAu11tPCF1cVlbW+v19fXpMQAAzqqqTnT32tbzF80b8wEA9hIRBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAxYKcKq6vKqeqCqHl3+vOwM644uax6tqqPLuZdV1cer6neq6mRVfXCVWQAALiarPhN2e5IHu/uaJA8ux39KVV2e5I4k1yW5Nskdm2LtZ7r7Lyb5gSR/o6puWnEeAICLwqoRdiTJPcv9e5K8Y5s1NyR5oLuf6e5nkzyQ5Mbu/np3//ck6e7nkzyc5OCK8wAAXBRWjbDXdPdTy/0/SPKabdZcleTxTcdPLOf+n6p6ZZK3Z+PZtG1V1a1VtV5V66dPn15paACAaQfOtqCqPpHku7a59L7NB93dVdXf7gBVdSDJf0ryb7v7sTOt6+67k9ydJGtra9/25wEA2E3OGmHd/dYzXauqP6yq13b3U1X12iRf2WbZk0netOn4YJJPbTq+O8mj3f2z5zIwAMBesOrLkceSHF3uH03yy9usOZ7k+qq6bHlD/vXLuVTVTyd5RZIfX3EOAICLyqoR9sEkb6uqR5O8dTlOVa1V1c8nSXc/k+Snkjy03O7s7meq6mA2XtI8nOThqvpsVf2DFecBALgoVPfF9/aqtbW1Xl9fnx4DAOCsqupEd69tPe9fzAcAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGrBRhVXV5VT1QVY8uf152hnVHlzWPVtXRba4fq6rfWmUWAICLyarPhN2e5MHuvibJg8vxn1JVlye5I8l1Sa5NcsfmWKuqv5PkuRXnAAC4qKwaYUeS3LPcvyfJO7ZZc0OSB7r7me5+NskDSW5Mkqp6eZKfSPLTK84BAHBRWTXCXtPdTy33/yDJa7ZZc1WSxzcdP7GcS5KfSvKvk3z9bJ+oqm6tqvWqWj99+vQKIwMAzDtwtgVV9Ykk37XNpfdtPujurqo+109cVX8lyfd29z+pqkNnW9/ddye5O0nW1tbO+fMAAOxGZ42w7n7rma5V1R9W1Wu7+6mqem2Sr2yz7Mkkb9p0fDDJp5L89SRrVfWlZY5XV9WnuvtNAQDY41Z9OfJYkm/9tuPRJL+8zZrjSa6vqsuWN+Rfn+R4d//77n5ddx9K8kNJfleAAQD7xaoR9sEkb6uqR5O8dTlOVa1V1c8nSXc/k433fj203O5czgEA7FvVffG9vWptba3X19enxwAAOKuqOtHda1vP+xfzAQAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABgQHX39Azftqo6neT3dvAhX5Xkqzv4eOwce7O72Z/dy97sbvZnd9vp/fnz3X3l1pMXZYTttKpa7+616Tn4/9mb3c3+7F72ZnezP7vbhdofL0cCAAwQYQAAA0TYhrunB+CM7M3uZn92L3uzu9mf3e2C7I/3hAEADPBMGADAgD0fYVV1Y1U9UlWnqur2ba5fWlX3Ldc/U1WHNl1773L+kaq64YIOvg+82L2pqrdV1Ymq+s3lzzdf8OH3gVW+d5br311Vz1XVey7Y0PvEij/Xvr+qfrWqTi7fQ99xQYffB1b42fZnq+qeZV9+u6ree8GH3+POYW/+ZlU9XFUvVNXNW64drapHl9vRHRmou/fsLcklSb6Q5HuSvCTJbyQ5vGXNP0ryH5b7tyS5b7l/eFl/aZKrl8e5ZPpr2iu3FffmB5K8brn/l5I8Of317LXbKvuz6fr9Sf5zkvdMfz176bbi986BJJ9L8peX4yv8XNtV+/OuJPcu91+W5EtJDk1/TXvldo57cyjJ9yf5j0lu3nT+8iSPLX9etty/bNWZ9vozYdcmOdXdj3X380nuTXJky5ojSe5Z7t+f5C1VVcv5e7v7G939xSSnlsdjZ7zovenuX+/uLy/nTyZ5aVVdekGm3j9W+d5JVb0jyRezsT/srFX25vokn+vu30iS7n66u795gebeL1bZn07ynVV1IMlLkzyf5I8uzNj7wln3pru/1N2fS/InWz72hiQPdPcz3f1skgeS3LjqQHs9wq5K8vim4yeWc9uu6e4XknwtG/91eC4fy4u3yt5s9qNJHu7ub5ynOferF70/VfXyJD+Z5AMXYM79aJXvnb+QpKvq+PKSyz+7APPuN6vsz/1J/jjJU0l+P8nPdPcz53vgfWSVv9fPSxMcWPUBYEpVvTHJh7LxX/fsHu9Pcld3P7c8McbucSDJDyX5wSRfT/JgVZ3o7gdnx2JxbZJvJnldNl7y+p9V9Ynufmx2LM6Xvf5M2JNJXr/p+OBybts1y1PAr0jy9Dl+LC/eKnuTqjqY5JeS/Fh3f+G8T7v/rLI/1yX5cFV9KcmPJ/nnVXXbeZ53P1llb55I8j+6+6vd/fUk/yXJXz3vE+8vq+zPu5L8t+7+P939lSSfTuJ/bbRzVvl7/bw0wV6PsIeSXFNVV1fVS7LxBshjW9YcS/Kt33K4Ockne+NdeMeS3LL8FsvVSa5J8msXaO794EXvTVW9MsnHk9ze3Z++UAPvMy96f7r7h7v7UHcfSvKzSf5Vd//cBZp7P1jl59rxJN9XVS9b/vL/W0k+f4Hm3i9W2Z/fT/LmJKmq70zy15L8zgWZen84l705k+NJrq+qy6rqsmy8AnN85Ymmf1vhfN+S/O0kv5uN34h433LuziQ/stz/jmz8BtepbETW92z62PctH/dIkpumv5a9dnuxe5PkX2TjfROf3XR79fTXs9duq3zvbHqM98dvR+6qvUnyd7PxCxO/leTD01/LXryt8LPt5cv5k9mI4386/bXstds57M0PZuMZ4z/OxrOTJzd97N9f9uxUkr+3E/P4F/MBAAbs9ZcjAQB2JREGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA/4vfQmEJjBOCDUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/Users/knf792/gits/nlp-course/nlp-book/_build/jupyter_execute/stat-nlp-book/exercises/language_models_7_2.png"
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "oov_train = inject_OOVs(train)\n",
    "oov_vocab = set(oov_train)\n",
    "oov_test = replace_OOVs(oov_vocab, test)\n",
    "bigram = NGramLM(oov_train,2)\n",
    "\n",
    "interval = [x/1000.0 for x in range(1, 100, 1)]\n",
    "perplexity_at_1 = perplexity(LaplaceLM(bigram, alpha=1.0), oov_test)\n",
    "\n",
    "def plot_perplexities(interval):\n",
    "    \"\"\"Plots the perplexity of LaplaceLM for every alpha in interval.\"\"\"\n",
    "    perplexities = [0.0 for alpha in interval]  # todo\n",
    "    plt.plot(interval, perplexities)\n",
    "    \n",
    "def find_optimal(low, high, epsilon=1e-6):\n",
    "    \"\"\"Returns the optimal pseudo count alpha within the interval [low, high] and the perplexity.\"\"\"\n",
    "    print(high, low)\n",
    "    if high - low < epsilon:\n",
    "        return 0.0  # todo\n",
    "    else:\n",
    "        return 0.0  # todo\n",
    "\n",
    "plot_perplexities(interval)        \n",
    "find_optimal(0.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 2</font>: Sanity Check LM\n",
    "Implement a method that tests whether a language model provides a valid probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-21T16:59:19.237379",
     "start_time": "2016-10-21T16:59:19.153304"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0661659877800471\n"
     ]
    }
   ],
   "source": [
    "def sanity_check(lm, *history):\n",
    "    \"\"\"Throws an AssertionError if lm does not define a valid probability distribution for all words \n",
    "    in the vocabulary.\"\"\"  \n",
    "    probability_mass = 1.0  # todo\n",
    "    assert abs(probability_mass - 1.0) < 1e-6, probability_mass\n",
    "\n",
    "unigram = NGramLM(oov_train,1)\n",
    "stupid = StupidBackoff(bigram, unigram, 0.1)\n",
    "print(sum([stupid.probability(word, 'the') for word in stupid.vocab]))\n",
    "sanity_check(stupid, 'the')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 3</font>: Subtract Count LM\n",
    "Develop and implement a language model that subtracts a count $d\\in[0,1]$ from each non-zero count in the training set. Let's first formalise this:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\#_{w=0}(h_n) &= \\sum_{w \\in V} \\mathbf{1}[\\counts{\\train}{h_n,w} = 0]\\\\\n",
    "\\#_{w>0}(h_n) &= \\sum_{w \\in V} \\mathbf{1}[\\counts{\\train}{h_n,w} > 0]\\\\\n",
    "\\prob(w|h_n) &= \n",
    "\\begin{cases}\n",
    "\\frac{\\counts{\\train}{h_n,w} - d}{\\counts{\\train}{h_n}}  & \\mbox{if }\\counts{\\train}{h_n,w} > 0 \\\\\\\\\n",
    "\\frac{???}{\\counts{\\train}{h_n}} & \\mbox{otherwise}\n",
    "\\end{cases}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-21T16:59:19.337884",
     "start_time": "2016-10-21T16:59:19.240468"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SubtractCount(CountLM):        \n",
    "    def __init__(self, base_lm, d):\n",
    "        super().__init__(base_lm.vocab, base_lm.order)\n",
    "        self.base_lm = base_lm\n",
    "        self.d = d            \n",
    "        self._counts = base_lm._counts  # not good style since it is a protected member\n",
    "        self.vocab = base_lm.vocab\n",
    "\n",
    "    def counts(self, word_and_history):\n",
    "        if self._counts[word_and_history] > 0:\n",
    "            return 0.0  # todo\n",
    "        else:\n",
    "            return 0.0  # todo\n",
    "\n",
    "    def norm(self, history):\n",
    "        return self.base_lm.norm(history)    \n",
    "    \n",
    "subtract_lm = SubtractCount(unigram, 0.1)\n",
    "oov_prob = subtract_lm.probability(OOV, 'the')\n",
    "rest_prob = sum([subtract_lm.probability(word, 'the') for word in subtract_lm.vocab])\n",
    "print(oov_prob + rest_prob)\n",
    "sanity_check(subtract_lm, 'the')\n",
    "perplexity(subtract_lm, oov_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 4</font>: Normalisation of Stupid LM\n",
    "Develop and implement a version of the [stupid language model](https://github.com/uclmr/stat-nlp-book/blob/python/statnlpbook/lm.py#L205) that provides probabilities summing up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-21T16:59:19.398354",
     "start_time": "2016-10-21T16:59:19.339446"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class StupidBackoffNormalized(LanguageModel):\n",
    "    def __init__(self, main, backoff, alpha):\n",
    "        super().__init__(main.vocab, main.order)\n",
    "        self.main = main\n",
    "        self.backoff = backoff\n",
    "        self.alpha = alpha               \n",
    "\n",
    "    def probability(self, word, *history):\n",
    "        return 0.0  # todo\n",
    "        \n",
    "less_stupid = StupidBackoffNormalized(bigram, unigram, 0.1)\n",
    "print(sum([less_stupid.probability(word, 'the') for word in less_stupid.vocab]))\n",
    "sanity_check(less_stupid, 'the')\n",
    "perplexity(less_stupid, oov_test)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}